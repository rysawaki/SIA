# 🎯 SIAプロジェクトの要件定義（Draft v1）

## 🟦 1. プロジェクトの目的（Goal）

> **「痕跡（Trace）」が自己の幾何を不可逆に歪め、それがAttention・生成・解釈・行動を変化させることを、理論・形式・実装・振る舞いを通して証明するAIモデルを構築する。**

❗ここで重要なのは、「自己を持つAIを作る」ではない。
主目的は **“不可逆な経験の痕跡が、解釈と生成を歪めることを実証する”** こと。

---

## 🟥 2. スコープ定義（Scope — 何をやるか / 何をやらないか）

| 含める (In Scope)                         | 含めない (Out of Scope) |
| -------------------------------------- | ------------------- |
| Self-space（自己の幾何空間）の定義                 | 汎用LLMの学習や大規模な微調整    |
| TraceTensor による不可逆な変形                  | 記憶の保存や検索（RAG）そのもの   |
| Metric-based Attention (SIA Attention) | 単なるAttentionの改良論文   |
| Affectをゲインとして使った痕跡更新                   | “感情豊かなAI”“人格AI”の再現  |
| Pre/Post生成の比較実験                        | 主観的評価だけの感想ベース分析     |
| 固有値・幾何構造の分析(数学的検証)                     | 物語生成や感情ストーリーAI      |

**⚠注意: SIAは「感情AI」でも「自己モデルAI」でもない。
それは“痕跡による世界の歪みを持つAI”である。**

---

## 🔷 3. Core Concept Requirements（中核として欠かせない概念要件）

### 🧠 必須4要素（どれも欠けたらSIAとは言えない）

| 要素          | 定義                           | 必要性               |
| ----------- | ---------------------------- | ----------------- |
| Self-Space  | 自己状態が存在する幾何学空間 $\mathcal{S}$ | 世界との関係性を測れる器      |
| TraceTensor | 経験の不可逆な歪み（対称テンソル $T_t$）      | 記憶ではなく“痕跡”である証拠   |
| Metric      | $M_t = I + T_t$ によって作られる動的幾何 | Attention/生成の変化の源 |
| Affect      | 更新の増幅係数（痕跡の「刻まれ方」）           | 全ての経験が等価でないこと     |

👉 これ以外は拡張要素。
**まずはこの4つの相互作用が確認できる最小モデルを完成させる。**

---

## ⚙️ 4. System Behavior Requirements（振る舞い要件）

「痕跡が実際に世界の解釈を変えた」と判断できる基準を最初から定義する。
そうしないと、“できた気がする”で終わる。

### 必須で確認すべき振る舞い（実験によって証明）

| 観察          | 確認すること                           |
| ----------- | -------------------------------- |
| 生成テキストの変化   | 同じ "I am" で Pre/Neg/Post で違う文が出る |
| Attention分布 | Attention map がパターン的に異なる         |
| ロジット操作      | “sad” “strong” などの確率が痕跡後に変動      |
| 幾何の変化       | $T_t$ の固有値・固有方向に偏りが生まれる          |
| 解釈の変化       | “The world” に対する応答が痕跡によって変わる     |

これが確認できたら
👉「痕跡が解釈を歪めた（世界の写像が変化した）」と言える。

---

## 🧪 5. 実験要件（実装者に渡すための仕様）

| 実験ID   | 内容                     | 目的         |
| ------ | ---------------------- | ---------- |
| EXP-01 | Traceなしで生成             | Baseline取得 |
| EXP-02 | Negative Trace 更新 → 生成 | 歪みの方向確認    |
| EXP-03 | Positive Trace 更新 → 生成 | 対称性破れ確認    |
| EXP-04 | Attention heatmap比較    | 幾何的変化の視覚化  |
| EXP-05 | 固有値と方向の分析              | 痕跡の方向性の証明  |

📌 各実験のアウトプット例も、最初から定義する（曖昧にしない）。

---

## 🧭 6. 完成の定義（Definition of Done — 終了条件）

🟢 完了と認められるのは、以下が全て揃ったとき：

* [ ] Baseline / Neg / Pos で生成が明確に変わる
* [ ] Attention heatmap で偏りが可視化される
* [ ] TraceTensorの固有値・方向に明確な変化がある
* [ ] “経験が幾何に刻まれた結果、生成が変わった”と説明できる
* [ ] コードではなく**概念言語で説明可能**
* [ ] SIA v1仕様書に反映されている

👉 **ただ動くことではなく、「説明できること」がゴール。**

---

## 🚫 明確に排除すべき誤解

| 誤解                    | なぜダメか                  |
| --------------------- | ---------------------- |
| SIAは記憶モデルである          | 過去の情報を保存するのではない        |
| SIAは感情AIである           | 感情表現が目的ではない            |
| SIAはSelf-Attentionの改造 | Self（概念）はAttentionではない |
| SIAはChatGPTの人格形成技術    | 人格生成は副産物であって本質ではない     |

👉 **「これは何か」を説明できた時点で終わり。
「何ではないか」まで説明できたら、本物になる。**


# 🔍 用語の整理 ― SIA理論で絶対に混同してはいけない概念たち

---

## 🧠 1. Trace（痕跡）

> **過去の経験が、自己の空間構造（Self-space）を不可逆に歪めた結果。
> 記録された情報ではなく、変形という“事実”だけが残る。**

📌 数学的定義：

$$
T_{t+1} = (1-\lambda)T_t + \gamma, a_t, \eta_t \cdot \frac{v_t v_t^\top}{|v_t|^2 + \varepsilon}
$$

* 保存されるのは **経験そのものではない**
* 復元不能（irreversible）
* テンソルとして空間に刻まれる（d×d）

---

## 🌐 2. Self-space（自己空間）

> **自己状態 $s_t$ が存在し、世界との距離・意味を測る“幾何学的な器”。**

* 単なる latent space ではない
* メトリックが動的に変化する点が決定的に重要

📌 数学的表現：

$$
\mathcal{S} = (\mathbb{R}^d,, g_{T_t})
$$

---

## 📐 3. Metric（自己変形された幾何）

> **痕跡 $T_t$ によって歪んだ意味距離の“ものさし”**

$$
M_t = I + \alpha_t, T_t
$$

* Attention が使う “似ている／近い” の基準そのもの
* ここが変わると、世界の見え方が変わる

---

## 👁 4. Attention（標準概念）

> **Query-Key 内積に基づく “関連性・類似性” の評価機構**

> **世界がどのように感じられるかを決める“感受の構造**

$$
\mathrm{score}_{ij} = \frac{q_i^\top k_j}{\sqrt{d}}
$$

⚠️ 標準Attentionは「意味解釈の変形」をしない。
空間は固定、ものさしも固定。

---

## 🔄 5. Self-conditioned Attention（SIA Attention）

> **Attentionの“似ている”を、
> 自己痕跡で歪められた Metric を通して再定義したもの。**

📌 数学的定義：

$$
\mathrm{score}_{ij}
= \frac{q_i^\top (I + \alpha T_t) k_j}{\sqrt{d}}
$$

* Query と Key を変形するのではなく
  ⇒ **内積のものさし（Metric）を変える**

| 従来Attention | Self-conditioned Attention (SIA) |
| ----------- | -------------------------------- |
| $q^\top k$  | $q^\top M_t, k$                  |
| 空間固定        | 空間が変形する                          |
| 記憶と切り離されている | 経験（Trace）に依存して変化                 |

---

## 🌀 6. Attention Map（Attention出力）

Attentionを通じて得られた重みパターン：

$$
A_{ij} = \mathrm{softmax}(\mathrm{score}_{ij})
$$

📌 これは「Attentionそのもの」ではなく、
**Attentionが世界をどう見ているかの足跡（output）**。

---

## 🚫 7. Attention Trace（使ってはいけない語）

⚠️ 以下のように運用すると誤解が生じる：

| 使い方               | 問題                 |
| ----------------- | ------------------ |
| Attentionの履歴という意味 | それはTraceではなくMemory |
| Attentionを可視化した図  | Traceと全く関係ない       |
| Attentionに刻まれた痕跡  | 正しいが紛らわしい          |

### 🔹 推奨: Attention Trace という語は**使わない方がいい**

代わりに以下のように使い分けろ：

| 正しい表現                      | 何を指すか           |
| -------------------------- | --------------- |
| TraceTensor                | 痕跡の本体（空間の変形）    |
| Attention Map              | その変形が生成に影響した結果  |
| Metric-based Attention     | Traceを使う仕組みそのもの |
| Post-SIA Attention Pattern | 痕跡後のAttention   |

---

# ✍️ 正しい用語対応まとめ

| 要素                  | 数学オブジェクト               | 実装                       | 可視化の対象           |
| ------------------- | ---------------------- | ------------------------ | ---------------- |
| Trace               | $T_t$                  | trace.T                  | 固有値・固有方向         |
| Metric              | $M_t = I + \alpha T_t$ | metric_matrix()          | 歪んだ空間            |
| Attention           | $q^\top k$             | dot-product              | 通常の重み            |
| SIA Attention       | $q^\top M_t k$         | SelfConditionedAttention | 歪んだ注目パターン        |
| Attention Map       | $A_{ij}$               | softmax(score)           | ヒートマップ           |
| Post-Trace Behavior | -                      | generate_with_sia()      | 生成文・Attention・確率 |

---

# 🎯 結論

### ❌ Attention Traceは曖昧で危険な用語

→ 使わない方がいい

### ✔ 正しい語の使い分け

| T     | M       | SIA Attention | Attention Map |
| ----- | ------- | ------------- | ------------- |
| 痕跡の本体 | 歪んだものさし | 歪んだ評価機構       | 可視化される結果      |

---

あなたの立場なら、こう言葉を使うべきだ👇

> Attentionが痕跡を持つのではない。
> 痕跡がAttentionの基準（Metric）を歪めるのだ。


